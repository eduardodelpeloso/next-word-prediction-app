out <- rbinom(50,1,0.5)
out
runif(10)
in <- matrix(runif(50*10000),50,10000)
input <- matrix(runif(50*10000),50,10000)
output <- rbinom(50,1,0.5)
rm(out)
dim(input)
input <- matrix(runif(50*10000),10000,50)
cor(output,input[,*])
cor(output,input[*,])
input[,*]
split(input,rep(1:ncol(input),each=nrow(input)))
split(input,rep(1:ncol(input),each=nrow(input)))[1]
cor(output,split(input,rep(1:ncol(input),each=nrow(input))))
cor(output,split(input,rep(1:nrow(input),each=ncol(input))))
split(input,rep(1:nrow(input),each=ncol(input)))
split(input,rep(1:nrow(input),each=ncol(input)))[1]
class(split(input,rep(1:nrow(input),each=ncol(input)))[1])
class(split(input,rep(1:nrow(input),each=ncol(input)))[1][1])
split(input,rep(1:nrow(input),each=ncol(input)))[1][1]
split(input,rep(1:nrow(input),each=ncol(input)))[1][1][1]
split(input,rep(1:nrow(input),each=ncol(input)))[1,1
]
split(input,rep(1:nrow(input),each=ncol(input)))[1]
split(input,rep(1:nrow(input),each=ncol(input)))[[1]]
split(input,rep(1:nrow(input),each=ncol(input)))[[1]][1]
cor(output,as.double(split(input,rep(1:nrow(input),each=ncol(input)))))
split(input,rep(1:nrow(input),each=ncol(input)))
cor(output,runif(50))
cor(output,runif(50))
cor(output,runif(50))
cor(output,runif(50))
cor(output,runif(50))
cor(output,runif(50))
cor(output,runif(50))
cor(output,runif(50))
split(input,rep(1:nrow(input),each=ncol(input)))
split(input,rep(1:nrow(input),each=ncol(input)))[[1]]
cor(output,split(input,rep(1:nrow(input),each=ncol(input)))[[1]])
corrs <- NULL
for i in 1:10000 {
for (i in 1:10000) {
corrs <- c(corrs, cor(output,split(input,rep(1:nrow(input),each=ncol(input)))[[i]])
}
corrs <- NULL
for (i in 1:10000) {
corrs <- c(corrs, cor(output,split(input,rep(1:nrow(input),each=ncol(input)))[[i]]))
}
id <- 1:10000
corrs2 <- rbind(id, corrs)
View(corrs2)
corrs2 <- cbind(id, corrs)
names(corrs2)
corrs2_df <- data.frame(x=corrs2[,1],y=corrs2[,2])
View(corrs2_df)
sorted_corrs2_df <- corrs2_df[order(-corrs2_df$y)]
sorted_corrs2_df <- corrs2_df[order(-corrs2_df$y),]
View(sorted_corrs2_df)
original <- rnorm(100)
hist(original)
sample(original, 100, replace = TRUE)
?sample
mean(original)
sd(original)
?rnorm
source('~/boot.R')
source('~/boot.R')
mean(boot_means)
mean(boot_sds)
mean(original)
sd(original)
source('~/boot.R')
hist(boot_means)
sd(boot_means)
mean(boot_sds)
high <- rnorm(100000)
hist(high)
random_means <- NULL
for (i in 1:100000) {
random_means <- c(random_means, mean(runif(40)))
}
hist(boot_means)
hist(random_means)
hist(boot_means, col=rgb(0.1,0.1,0.1,0.5),xlim=c(-1,1), ylim=c(0,25000))
hist(random_means, col=rgb(0.8,0.8,0.8,0.5), add=T)
random_means <- NULL
for (i in 1:100000) {
random_means <- c(random_means, mean(rnorm(40)))
}
hist(boot_means)
hist(random_means)
hist(boot_means, col=rgb(0.1,0.1,0.1,0.5),xlim=c(-1,1), ylim=c(0,25000))
hist(random_means, col=rgb(0.8,0.8,0.8,0.5), add=T)
sd(random_means)
sd(boot_means)
9^9
5^5
6^6
7^7
(1-1/50)^50
(1-1/500)^500
(1-1/5000)^5000
(1-(1/5000))^5000
(1-(1/5))^5
(1-(1/5))**5
2**3
23
2^3
(1-(1/2))**2
(1-(1/3))**3
x <- 1:100
y <- (1-(1/x))^x
plot(x,y)
(1-(1/50000))^50000
library(ISLR)
library(boot)
?cv.glm
plot(mpg~horsepower,data=Auto)
View(Auto)
glm.fit <- glm(mpg~horsepower, data = Auto)
summary(glm.fit)
result <- cv.glm(Auto,glm.fit)
result
names(result)
loocv=function(fit) {
h=lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
loocv(glm.fit)
cv.glm(Auto,glm.fit)$delta
cv.error=rep(0,5)
cv.error
degree=1:5
for (d in degree) {
glm.fit=glm(mpg~poly(horsepower,d),data=Auto)
cv.error[d]=loocv(glm.fit)
}
plot(degree,cv.error,type='b')
cv.error10=rep(0,10)
for (d in degree) {
glm.fit=glm(mpg~poly(horsepower,d),data=Auto)
cv.error10[d]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
cv.error10=rep(0,5)
for (d in degree) {
glm.fit=glm(mpg~poly(horsepower,d),data=Auto)
cv.error10[d]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
lines(degree,cv.error10,type='b',col='red')
rm(list=ls())
alpha=function(x,y) {
vx=var(x)
vy=var(y)
cxy=cov(x,y)
(vy-vx)/(vx+vy-2*cxy)
}
Portfolio
alpha(Portfolio$X,Portfolio$Y)
alpha
alpha=function(x,y) {
vx=var(x)
vy=var(y)
cxy=cov(x,y)
(vy-cxy)/(vx+vy-2*cxy)
}
alpha(Portfolio$X,Portfolio$Y)
alpha.fn=function(data,index) {
with(data[index,], alpha(X,Y))
}
alpha.fn(Portfolio,1:100)
alpha.fn(Portfolio,1:50)
set.seed(1)
alpha.fn(Portfolio,sample(1:100,100,replace=TRUE))
boot.out=boot(Portfolio, alpha.fn,R=1000)
boot.out
plot(boot.out)
seq(263)
set.seed(1)
train=sample(seq(263),180,replace = FALSE)
train
Hitters
library(ISLR)
summary(Hitters)
Hitters=na.omit(Hitters)
library(leaps)
a=-5:5
a
sum(a)
sqrt(sum(a^2))
abs(a)
sum(abs(a))
sum(a^2)
install.packages(c("glmnet", "kSamples", "NLP", "RcppEigen", "rmarkdown", "topicmodels"))
install.packages("devtools")
devtools::install_github(c("rstudio/rmarkdown", "hadley/bookdown", "hadley/lineprof"))
devtools::install_github(c("rstudio/rmarkdown", "hadley/bookdown", "hadley/lineprof"))
sudo apt-get install pandoc-citeproc
dir()
?boost
library(tree)
?boost
library(randomForest)
?boost
library(gbm)
install.packages("gbm")
library(gbm)
?boost
?boost.boston
?gbm
69-57
(12/69)+0.66
library(ISLR)
libray(tree())
libray(tree
)
library(tree)
attach(Carseats)
?Carseats
hist(Sales)
View(Carseats)
High=ifelse(Sales<=8,"No","Yes")
dim(Carseats)
Carseats=data.frame(Carseats, High)
View(Carseats)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats
set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
plot(tree.carseats);text(tree.carseats,pretty=0)
tree.pred=predict(tree.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(72+33)/150
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
plot(cv.carseats)
prune.carseats=prune.misclass(tree.carseats,best=13)
plot(prune.carseats);text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(72+32)/150
require(randomForest)
require(MASS)
set.seed(101)
dim(Boston)
train=sample(1:nrow(Boston),300)
?Boston
View(Boston)
hist(Boston$medv)
rf.boston=randomForest(medv~.,data=Boston,subset=train)
rf.boston
oob.err=double(13)
test.err=double(13)
for(mtry in 1:13){
fit=randomForest(medv~.,data=Boston,subset=train,mtry=mtry,ntree=400)
oob.err[mtry]=fit$mse[400]
pred=predict(fit,Boston[-train,])
test.err[mtry]=with(Boston[-train,],mean((medv-pred)^2))
cat(mtry," ")
}
matplot(1:mtry,cbind(test.err,oob.err),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
rf.boston=randomForest(medv~.,data=Boston,subset=train,mtry=4)
rf.boston
oob.err=double(13)
test.err=double(13)
for(mtry in 1:13){
fit=randomForest(medv~.,data=Boston,subset=train,mtry=mtry,ntree=5000)
oob.err[mtry]=fit$mse[400]
pred=predict(fit,Boston[-train,])
test.err[mtry]=with(Boston[-train,],mean((medv-pred)^2))
cat(mtry," ")
}
matplot(1:mtry,cbind(test.err,oob.err),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
14/26
require(gbm)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.boston)
summary(fit)
rf.boston=randomForest(medv~.,data=Boston,subset=train)
rf.boston
rf.boston=randomForest(medv~.,data=Boston,subset=train)
rf.boston
rf.boston=randomForest(medv~rm+lstat,data=Boston,subset=train)
rf.boston
rf2.boston=randomForest(medv~rm+lstat+dis,data=Boston,subset=train)
rf0.boston=randomForest(medv~rm,data=Boston,subset=train)
rf1.boston=randomForest(medv~rm+lstat,data=Boston,subset=train)
rf2.boston=randomForest(medv~rm+lstat+dis+crim,data=Boston,subset=train)
anova(rf0,rf1,rf2,rf3)
rf3.boston=randomForest(medv~rm+lstat+dis+crim,data=Boston,subset=train)
rf2.boston=randomForest(medv~rm+lstat+dis,data=Boston,subset=train)
anova(rf0.boston,rf1.boston,rf2.boston,rf3.boston)
summary(boost.boston)
summary(boost.boston)
plot(boost.boston,i="lstat")
plot(boost.boston,i="rm")
n.trees=seq(from=100,to=10000,by=100)
predmat=predict(boost.boston,newdata=Boston[-train,],n.trees=n.trees)
dim(predmat)
berr=with(Boston[-train,],apply( (predmat-medv)^2,2,mean))
plot(n.trees,berr,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error")
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=100000,shrinkage=0.01,interaction.depth=4)
summary(boost.boston)
n.trees=seq(from=1000,to=100000,by=1000)
predmat=predict(boost.boston,newdata=Boston[-train,],n.trees=n.trees)
dim(predmat)
berr=with(Boston[-train,],apply( (predmat-medv)^2,2,mean))
plot(n.trees,berr,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error")
library(e1071)
?"e1071-deprecated"
source('C:/Users/eduardo.peloso/Dropbox/Data Science/R/Parallelism/timing_parallelism.R')
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
source('C:/Users/eduardo.peloso/Dropbox/Data Science/R/Parallelism/timing_parallelism.R')
source('C:/Users/eduardo.peloso/Dropbox/Data Science/R/Parallelism/timing_parallelism.R')
source('C:/Users/eduardo.peloso/Dropbox/Data Science/R/Parallelism/timing_parallelism_3.R')
source('C:/Users/eduardo.peloso/Dropbox/Data Science/R/Parallelism/timing_parallelism_2.R')
rm(list=ls())
source('C:/Users/eduardo.peloso/Dropbox/Data Science/R/Parallelism/timing_parallelism_3.R')
source('C:/Users/eduardo.peloso/Dropbox/Data Science/R/Parallelism/timing_parallelism.R')
install.packages(c("glmnet", "installr"))
square <- function(x)
{}
square <- function(x) {
x^2
}
square(2)
package.skeleton(())
package.skeleton()
dir()
pwd
getwd()
package.skeleton("advancedMath")
square <- function(x) {
x^2
}
package.skeleton("advancedMath")
pwd
ls()
dir()
system("R CMD build advancedMath")
library(RWeka)
install.packages("RWeka")
library(RWeka)
library(RWeka)
?RWeka
??RWeka
gc()
?gc
library(tm)
?gc
gc()
y=c(3,8,6,20,24,16,12,24,60,10,24,28,48,40,24,36,24,18,60,16,30,48,24,100,84,72,48,14,120,30,48,40,36,80,24,76,18,56,60)
x=2:40
plot(x,y)
lines(x,y)
y=c(3,8,6,20,24,16,12,24,60,10,24,28,48,40,24,36,24,18,60,16,30,48,24,100,84,72,48,14,120,30,48,40,36,80,24,76,18,56,60,40,48,88,30,120,48,32,24,112,300,72,84,108,72,20,48,72,42,58,120,60,30,48,96,140,120,136,36,48,240,70,24,148,228,200,18,80,168,78,120,216,120,168,48,180,264,56,60,44,120,112,48,120,96,180,48,196,336,120,300,50,72,208,84,80,108,72,72,108,60,152,48,76,72,240,42,168,174,144,120,110,60,40,30,500,48,256,192,88,420,130,120,144,408,360,36,276,48,46,240,32,210,140,24,140,444,112,228,148,600,50,36,72,240,60,168,316,78,216,240,48,216,328,120,40,168,336,48,364,180,72,264,348,168,400,120,232,132,178,120,90,336,120,48,380,120,180,96,144,180,190,96,388,588,280,336,396,120,22,300,136,150,112,72,40,624,48,168,90,240,42,108,280,72,440,72,240,108,296,60,252,456,448,48,600,228,456,72,114,240,80,84,52,168,160,174,312,144,238,120,240,330,648,60,560,120,252,60,168,1500,250,48,240,768,360,384,516,264,304,420,168,390,176,120,540,144,88,408,268,360,270,72,112,276,100,48,556,138,120,240,56,96,568,210,360,420,80,48,612,420,392,444,588,336,580,228,360,444,336,600,176,150,200,72,60,72,88,240,208,60,310,168,628,948,240,78,636,216,70,480,72,48,36,216,700,984,216,120,32,120,110,168,456,336,680,48,676,1092,152,180,30,72,784,264,240,348,232,168,174,1200,504,240,236,696,140,132,144,534,358,120,342,90,440,336,740,120,736,48,120,1140,432,120,748,180,1000,96,28,144,378,180,256,570,768,192,80,1164,264,588,388,840,144,336,520,396,780,120,796,66,144,600,200,408,420,150,1080,336,380,72,408,120,552,624,464,48,840,336,184,90,418,240,84,42,96,108,900,840,240,72,280,1320,430,72,868,240,280,108,144,888,438,60,336,252,888,456,220,1344,296,96,448,600,40,228,200,456,560,72,916,114,72,240,46,240,928,168,120,156,936,168,272,480,632,348,440,312,900,144,216,714,478,240,532,240,48,330,980,648,976,60,328,1680,490,120,252,252,120,120,560,168,498,1500)
x=2:500
plot(x,y)
lines(x,y)
a <- c(1,2,3)
a[1]
setwd('C:\\Users\\eduardo.peloso\\Dropbox\\Data Science\\Coursera Data Science Specialization\\10 - Capstone\\WordPredict\\data')
dir()
a <- readRDS('bigrams_cut_2_char.Rds')
b <- readRDS('bigrams_cut_2_char.Rds')
identical(a,b)
